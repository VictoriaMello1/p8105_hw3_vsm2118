---
title: "HW 3 Data Science"
author: "Victoria Mello (vsm2118)"
date: "October 14, 2023"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1


#### Read in the data

```{r}
data("instacart")

instacart = 
  instacart |> 
  as_tibble()
```

#### Answer questions about the data

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row resprenting a single product from an instacart order. Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. In total, there are `r instacart |> select(product_id) |> distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

Below is a table summarizing the number of items ordered from aisle. In total, there are 134 aisles, with fresh vegetables and fresh fruits holding the most items ordered by far.

```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

Next is a plot that shows the number of items ordered in each aisle. Here, aisles are ordered by ascending number of items.

```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Our next table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and includes the number of times each item is ordered in your table.

```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

Finally is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. This table has been formatted in an untidy manner for human readers. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```

## Problem 2


Data Cleaning
```{r}
data("brfss_smart2010")

# Data cleaning
brfss_data_cleaned <- brfss_smart2010 %>%
    janitor::clean_names() %>% 
    filter(topic == "Overall Health") %>%
    filter(response %in% c("Excellent", "Very Good", "Good", "Fair", "Poor")) %>%
    rename(state = locationabbr) %>% 
    mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE))

variable.names(brfss_data_cleaned)
```


In 2002 and 2010, which states were observed at 7 or more locations?
```{r}

# States observed at 7 or more locations in 2002
states_2002 <- brfss_data_cleaned %>%
  filter(year == 2002) %>%
  group_by(state) %>%
  summarize(count = n()) %>%
  filter(count >= 7) %>%
  arrange(desc(count))

# States observed at 7 or more locations in 2010
states_2010 <- brfss_data_cleaned %>%
  filter(year == 2010) %>%
  group_by(state) %>%
  summarize(count = n()) %>%
  filter(count >= 7) %>%
  arrange(desc(count))

knitr::kable(states_2002, caption =  "States with 7 or more observations in 2002", format = "markdown")
knitr::kable(states_2010, caption =  "States with 7 or more observations in 2010", format = "markdown")

```

In 2002 a total of 36 states were observed at 7 or more locations. The states observed at the most locations in 2002 were PA with 40, followed by MA and NJ both having 32. By 2010, the total number of states observed at 7 or more locations increased to 45. The states observed at the most locations in 2010 were FL with 164, followed by NJ with 76, and TX with 64 locations.


Dataset limited to Excellent responses and a spaghetti plot:
```{r}

excellent_avg <- brfss_data_cleaned %>%
  filter(response == "Excellent") %>%
  group_by(state, year) %>%
  summarize(avg_data_value = mean(data_value)) %>%
  ggplot(aes(x = year, y = avg_data_value, group = state, color = state)) +
  geom_line() +
  labs(
    title = "Average Data Value Over Time (Excellent Responses) by State",
    x = "Year",
    y = "Average Data Value"
  ) +
  theme_minimal()

```
The plot provides a useful tool for visualizing and comparing trends in the average data value of "Excellent" responses between states over time. It allows for a comparison between states over the years 2002 to 2010. However, due to there being 50 states, the plot is quite busy and it is challenging to distinguish between the lines of individual states. One observation that can be made from the plot is that most states appear to be following a similar fluctuating trend for the average "Excellent" responses to the "Overall Health" topic over time. However, without specific data points or a clearer view, it's difficult to make more detailed observations or conclusions.


Two-panel scatterplot showing the distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State in the years 2006 and 2010:
```{r}
# Filter the dataset to include only NY State and the years 2006 and 2010
ny_data <- brfss_data_cleaned %>%
  filter(state == "NY" & year %in% c(2006, 2010) & response %in% c("Poor", "Fair", "Good", "Very Good", "Excellent"))

# Create the first plot: scatter plot of data_value vs. response for 2006
ny_data_2006 <- ny_data %>%
  filter(year == 2006)

plot_2006 <- ggplot(ny_data_2006, aes(x = response, y = data_value, color = locationdesc, size = data_value)) +
  geom_point(alpha = 0.5) +
  scale_color_discrete(name = "Location") +
  scale_size_continuous(range = c(1, 10)) +
  labs(title = "Distribution of Data Value by Location in New York State (2006)",
       x = "Response",
       y = "Data Value",
       color = "Location",
       size = "Data Value") +
  theme_minimal()

# Create the second plot: scatter plot of data_value vs. response for 2010
ny_data_2010 <- ny_data %>%
  filter(year == 2010)

plot_2010 <- ggplot(ny_data_2010, aes(x = response, y = data_value, color = locationdesc, size = data_value)) +
  geom_point(alpha = 0.5) +
  scale_color_discrete(name = "Location") +
  scale_size_continuous(range = c(1, 10)) +
  labs(title = "Distribution of Data Value by Location in New York State (2010)",
       x = "Response",
       y = "Data Value",
       color = "Location",
       size = "Data Value") +
  theme_minimal()

# Combine the two plots into a single multipanel plot
plot_combined <- plot_2006 + plot_2010

plot_combined


```
  COMMENT ON RESULTS!!!


## Problem 3 


```{r}

```

