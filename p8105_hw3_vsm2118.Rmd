---
title: "HW 3 Data Science"
author: "Victoria Mello (vsm2118)"
date: "October 14, 2023"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1


#### Read in the data

```{r}
data("instacart")

instacart = 
  instacart |> 
  as_tibble()
```

#### Answer questions about the data

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row resprenting a single product from an instacart order. Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. In total, there are `r instacart |> select(product_id) |> distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

Below is a table summarizing the number of items ordered from aisle. In total, there are 134 aisles, with fresh vegetables and fresh fruits holding the most items ordered by far.

```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

Next is a plot that shows the number of items ordered in each aisle. Here, aisles are ordered by ascending number of items.

```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Our next table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and includes the number of times each item is ordered in your table.

```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

Finally is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. This table has been formatted in an untidy manner for human readers. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```

## Problem 2


Data Cleaning
```{r}
data("brfss_smart2010")

# Data cleaning
brfss_data_cleaned <- brfss_smart2010 %>%
    janitor::clean_names() %>% 
    filter(topic == "Overall Health") %>%
    filter(response %in% c("Excellent", "Very Good", "Good", "Fair", "Poor")) %>%
    rename(state = locationabbr) %>% 
    mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE))

variable.names(brfss_data_cleaned)
```


In 2002 and 2010, which states were observed at 7 or more locations?
```{r}

# States observed at 7 or more locations in 2002
states_2002 <- brfss_data_cleaned %>%
  filter(year == 2002) %>%
  group_by(state) %>%
  summarize(count = n()) %>%
  filter(count >= 7) %>%
  arrange(desc(count))

# States observed at 7 or more locations in 2010
states_2010 <- brfss_data_cleaned %>%
  filter(year == 2010) %>%
  group_by(state) %>%
  summarize(count = n()) %>%
  filter(count >= 7) %>%
  arrange(desc(count))

knitr::kable(states_2002, caption =  "States with 7 or more observations in 2002", format = "markdown")
knitr::kable(states_2010, caption =  "States with 7 or more observations in 2010", format = "markdown")

```

In 2002 a total of 36 states were observed at 7 or more locations. The states observed at the most locations in 2002 were PA with 40, followed by MA and NJ both having 32. By 2010, the total number of states observed at 7 or more locations increased to 45. The states observed at the most locations in 2010 were FL with 164, followed by NJ with 76, and TX with 64 locations.


Dataset limited to Excellent responses and a spaghetti plot:
```{r}

excellent_avg <- brfss_data_cleaned %>%
  filter(response == "Excellent") %>%
  group_by(state, year) %>%
  summarize(avg_data_value = mean(data_value)) %>%
  ggplot(aes(x = year, y = avg_data_value, group = state, color = state)) +
  geom_line() +
  labs(
    title = "Average Data Value Over Time (Excellent Responses) by State",
    x = "Year",
    y = "Average Data Value"
  ) +
  theme_minimal()

```
The plot provides a useful tool for visualizing and comparing trends in the average data value of "Excellent" responses between states over time. It allows for a comparison between states over the years 2002 to 2010. However, due to there being 50 states, the plot is quite busy and it is challenging to distinguish between the lines of individual states. One observation that can be made from the plot is that most states appear to be following a similar fluctuating trend for the average "Excellent" responses to the "Overall Health" topic over time. However, without specific data points or a clearer view, it's difficult to make more detailed observations or conclusions.


Two-panel scatterplot showing the distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State in the years 2006 and 2010:
```{r}
# Filter the dataset to include only NY State and the years 2006 and 2010
ny_data <- brfss_data_cleaned %>%
  filter(state == "NY" & year %in% c(2006, 2010) & response %in% c("Poor", "Fair", "Good", "Very Good", "Excellent"))

# Create the first plot: scatter plot of data_value vs. response for 2006
ny_data_2006 <- ny_data %>%
  filter(year == 2006)

plot_2006 <- ggplot(ny_data_2006, aes(x = response, y = data_value, color = locationdesc, size = data_value)) +
  geom_point(alpha = 0.5) +
  scale_color_discrete(name = "Location") +
  scale_size_continuous(range = c(1, 10)) +
  labs(title = "Distribution of Data Value by Location in New York State (2006)",
       x = "Response",
       y = "Data Value",
       color = "Location",
       size = "Data Value") +
  theme_minimal()

# Create the second plot: scatter plot of data_value vs. response for 2010
ny_data_2010 <- ny_data %>%
  filter(year == 2010)

plot_2010 <- ggplot(ny_data_2010, aes(x = response, y = data_value, color = locationdesc, size = data_value)) +
  geom_point(alpha = 0.5) +
  scale_color_discrete(name = "Location") +
  scale_size_continuous(range = c(1, 10)) +
  labs(title = "Distribution of Data Value by Location in New York State (2010)",
       x = "Response",
       y = "Data Value",
       color = "Location",
       size = "Data Value") +
  theme_minimal() 

# Combine the two plots into a single multipanel plot
plot_combined <- plot_2006 + plot_2010

ggsave("combined_plot.png", plot_combined, width = 12, height = 6, units = "in")
knitr::include_graphics("combined_plot.png")

```
As seen in the two panel scatterplot showing the distribution of data_value for responses (“Poor” to “Excellent”) among counties in NY State for the years 2006 and 2010, the "Good" response option to the question "How is your general health?" was the most common response, followed by "Excellent", "Fair", and "Poor" in both years. Data from 2010 has information on a greater number of NY counties than the 2006 dataset does, including information for these additional counties: Bronx, Erie, and Monroe counties. 
#### Finish comment with which NY counties had highest vs lowest general health in each year


## Problem 3 

```{r}
# Load demographic data
demographics <- read.csv("nhanes_covar.csv", skip = 4)
view(demographics)

# Load accelerometer data
accelerometer <- read.csv("nhanes_accel.csv")
view(accelerometer)

# Tidy demographic data
demographics <- demographics %>%
  janitor::clean_names() %>%
  drop_na() %>%
  filter(age >= 21) %>%
  mutate(education = case_when(
    education == 1 ~ "Less than high school",
    education == 2 ~ "High school equivalent",
    education == 3 ~ "More than high school"
  ),
  sex = case_when(
    sex == 1 ~ "Male",
    sex == 2 ~ "Female"
  ))
view(demographics)

# Tidy accelerometer data -- FIX THIS !!!
reshaped_accelerometer <- accelerometer %>%
  janitor::clean_names() %>% 
  pivot_longer(
    cols = starts_with("min"),
    names_to = "minute",
    values_to = "activity_level"
  ) %>%
  mutate(minute = as.integer(gsub("min", "", minute)))


# Merge the reshaped accelerometer data with the demographics dataset using SEQN
merged_data <- demographics %>%
  inner_join(reshaped_accelerometer, by = "seqn")

view(merged_data)
```


Table for the number of men and women in each education category, and a visualization of age distributions for men and women across education categories:
```{r}
# Create sex v education table
education_summary <- merged_data %>%
  group_by(education, sex) %>%
  summarize(
    count = n()
  ) %>%
  ungroup() 

# Bar chart depicting table 
education_summary %>%
  ggplot(aes(x = education, y = count, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Number of Men and Women in Each Education Category", x = "Education Category", y = "Count") +
  theme_minimal()

# Create a histogram for age distributions by gender and education category
age_distribution_plot <- merged_data %>%
  ggplot(aes(x = age, fill = sex)) +
  geom_histogram(binwidth = 5, position = "dodge") +
  facet_grid(sex ~ education) +
  labs(title = "Age Distributions by Gender and Education Category", x = "Age", y = "Count") +
  theme_minimal()

# View the table and plots
education_summary
age_distribution_plot
```
 -- COMMENT On table and plot 


```{r}
# Aggregate total activity for each participant
total_activity <- merged_data %>%
  group_by(seqn, age, sex, education) %>%
  summarise(total_activity = sum(activity_level))

# Plot total activity by age, gender, and education level
total_activity <- ggplot(total_activity, aes(x = age, y = total_activity)) +
  geom_point(aes(color = sex)) +
  facet_wrap(~education) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  labs(title = "Total Activity by Age, Gender, and Education Level",
       x = "Age",
       y = "Total Activity",
       color = "Gender") +
  theme_minimal()

total_activity
```


```{r}
# Aggregate the data to an hourly level
hourly_data <- merged_data %>%
  group_by(education, sex, hour = minute %/% 60) %>%
  summarize(activity_level = mean(activity_level)) 

# Create the 24-hour activity time course plot
activity_plot <- hourly_data %>%
  ggplot(aes(x = hour, y = activity_level, color = sex)) +
  geom_line() +
  facet_wrap(~education) +  # 3 panels, one for each education level
  labs(title = "24-Hour Activity Time Courses by Education Level",
       x = "Hour of the Day",
       y = "Activity Level",
       color = "Gender") +
  scale_x_continuous(breaks = 0:24) +  # Set breaks for 0 to 24 (military time)
  theme_minimal() 

activity_plot
```

